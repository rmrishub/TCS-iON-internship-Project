import cv2
import numpy as np
import pytesseract
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed
from sklearn.model_selection import train_test_split
import os
from PIL import Image
import matplotlib.pyplot as plt

# Load and preprocess image
def preprocess_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale
    image = cv2.GaussianBlur(image, (5,5), 0)  # Apply Gaussian blur to reduce noise
    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  # Thresholding
    return thresh

# Extract text using Tesseract OCR
def extract_text(image_path):
    processed_image = preprocess_image(image_path)
    text = pytesseract.image_to_string(processed_image, config='--psm 6')  # Extract text
    return text

# Load dataset (IAM Handwriting Dataset or custom)
def load_dataset(dataset_path):
    images = []
    labels = []
    
    for file in os.listdir(dataset_path):
        if file.endswith(".png") or file.endswith(".jpg"):
            img_path = os.path.join(dataset_path, file)
            img = preprocess_image(img_path)
            images.append(img)
            labels.append(file.split('.')[0])  # Use file name as label (or load labels separately)
    
    images = np.array(images).reshape(-1, 128, 32, 1) / 255.0  # Normalize images
    return images, labels

# Build CNN-LSTM Model
def build_model():
    model = keras.Sequential([
        TimeDistributed(Conv2D(32, (3,3), activation='relu', padding='same'), input_shape=(128, 32, 1)),
        TimeDistributed(MaxPooling2D((2,2))),
        TimeDistributed(Flatten()),
        LSTM(64, return_sequences=True),
        LSTM(64),
        Dense(128, activation='relu'),
        Dense(26, activation='softmax')  # Assuming A-Z classification (Modify for full text)
    ])
    
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Train the model
def train_model():
    dataset_path = "path/to/handwriting_dataset"  # Replace with dataset path
    images, labels = load_dataset(dataset_path)
    
    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)
    model = build_model()
    
    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))
    model.save("handwriting_model.h5")  # Save trained model
    return model

# Run the pipeline
if __name__ == "__main__":
    # Extract text using OCR
    image_path = "sample_handwritten_image.jpg"
    extracted_text = extract_text(image_path)
    print("Extracted Text:", extracted_text)
    
    # Train and use deep learning model
    model = train_model()
    print("Model Training Complete!")
